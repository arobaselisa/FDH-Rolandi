{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Names, Scenes and Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import collections\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_range(path, attribute):\n",
    "    ''' Defining the ranges of the first and second pages '''\n",
    "    # Original image\n",
    "    shape = cv2.imread(path,0).shape\n",
    "    \n",
    "    # Range of x_0\n",
    "    x_0_lower = shape[1]*dict_attribute[attribute]['page_0_lower']\n",
    "    x_0_upper = shape[1]*dict_attribute[attribute]['page_0_upper']\n",
    "    # Range of x_1\n",
    "    x_1_lower = shape[1]*dict_attribute[attribute]['page_1_lower'] \n",
    "    x_1_upper = shape[1]*dict_attribute[attribute]['page_1_upper']  \n",
    "\n",
    "    return x_0_lower, x_0_upper, x_1_lower, x_1_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_x(coord, x_0_lower, x_0_upper, x_1_lower, x_1_upper):  \n",
    "    ''' Returns the page where the word is\n",
    "        0 in the first page\n",
    "        1 in the second page\n",
    "        -1 if not in the range \n",
    "    '''\n",
    "    if coord >= x_0_lower and coord <= x_0_upper:\n",
    "        return 0\n",
    "    elif coord >= x_1_lower and coord <= x_1_upper:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bounds(text, dict_bounds, mask, x_0_lower, x_0_upper, x_1_lower, x_1_upper, attribute):\n",
    "    ''' Finds the names and bounds in the image '''\n",
    "    proba = np.array([])\n",
    "    \n",
    "    # Defining the portion of the height of the box we want to keep\n",
    "    ratio_y = int((text['Bottom_Right_Y'] - text['Top_Left_Y'])*dict_attribute[attribute]['width_box'])\n",
    "    # Defining the portion of the width of the box we want to keep\n",
    "    ratio_x = int((text['Bottom_Right_X'] - text['Top_Left_X'])*dict_attribute[attribute]['height_box'])\n",
    "    \n",
    "    # Going through every pixel of the reduced box\n",
    "    for y in range(text['Top_Left_Y'] + ratio_y, text['Bottom_Right_Y'] - ratio_y):\n",
    "        for x in range(text['Top_Left_X'] + ratio_x, text['Bottom_Right_X'] - ratio_x):\n",
    "            # Find their associated probability of being a name\n",
    "            proba = np.append(proba, mask[y][x])\n",
    "            \n",
    "    # Finding the mean probability of being the corresponding attribute for all the pixels in the reduced box        \n",
    "    mean = proba.mean()\n",
    "    if mean > dict_attribute[attribute]['mean_proba_threshold']:\n",
    "        # Depending on coord_x, append extracted text and bounds on page 0 (left) or 1 (right) \n",
    "        coord_x = change_x(text['Top_Left_X'], x_0_lower, x_0_upper, x_1_lower, x_1_upper)\n",
    "        if coord_x != -1:\n",
    "            if coord_x in dict_bounds:\n",
    "                dict_bounds[coord_x].append((text['Top_Left_Y'], attribute, text['Text']))\n",
    "            else:    \n",
    "                dict_bounds[coord_x] = [(text['Top_Left_Y'], attribute, text['Text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_attributes_one_image(page):\n",
    "    ''' Returns the attributes and bounds in one image '''\n",
    "    \n",
    "    # Data from segmentation\n",
    "    segmentation_path = \"./data/Antigone/1_Segmentation_results/\" + page + \".npy\"\n",
    "    data = np.load(segmentation_path)\n",
    "    \n",
    "    dict_bounds = dict()\n",
    "    for i, attribute in enumerate(dict_attribute.keys()):\n",
    "        # Create x ranges\n",
    "        x_0_lower, x_0_upper, x_1_lower, x_1_upper = define_range(\"./data/Antigone/0_Images/\" + page + \".jpg\", attribute)\n",
    "        \n",
    "        # Threshold for attributes segmentation\n",
    "        mask = np.where(data[i+1]>dict_attribute[attribute]['ocr_proba_threshold'],1,0).astype(np.uint8)\n",
    "\n",
    "        # Load results from OCR\n",
    "        image_df = pd.read_csv('./data/Antigone/2_OCR_results/annotations_' + page + '.csv', index_col=0)\n",
    "\n",
    "        # Find the attributes and bounds\n",
    "        image_df.apply(lambda row: find_bounds(row, dict_bounds, mask, x_0_lower, x_0_upper, x_1_lower, x_1_upper, attribute), axis=1)\n",
    "\n",
    "    return dict_bounds\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_dict(dictionnary):\n",
    "    ''' Returns ordered dictionnary of bounds per pages and per coordinates '''\n",
    "    for pages in dictionnary.values():\n",
    "        for ind in [0,1]:\n",
    "            if ind in pages.keys():\n",
    "                pages[ind].sort(key=lambda x: x[0])\n",
    "    return sorted(dictionnary.items(), key = lambda kv:(int(kv[0][1:]), kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_in_json(dictionnary, path):\n",
    "    ''' Saves ordered dictionnary of bounds per pages and per coordinates in a json file'''\n",
    "    with open(path, \"w\") as outfile:  \n",
    "        json.dump(dictionnary, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_in_dict(path):\n",
    "    ''' Loads ordered dictionnary of bounds per pages and per coordinates from a json file'''\n",
    "    with open(path) as json_file: \n",
    "        return json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define attributes to extract in images as well as their parameters\n",
    "dict_attribute = {'Name': {'page_0_lower': 0, \n",
    "                            'page_0_upper':4/10, \n",
    "                            'page_1_lower':4/10, \n",
    "                            'page_1_upper':7/10,\n",
    "                            'width_box': 0.4,\n",
    "                            'height_box':0.4,\n",
    "                            'ocr_proba_threshold':0.2, \n",
    "                            'mean_proba_threshold':0.7},\n",
    "                   'Scene': {'page_0_lower': 0, \n",
    "                             'page_0_upper':4/10, \n",
    "                             'page_1_lower':5/10, \n",
    "                             'page_1_upper':8/10, \n",
    "                             'width_box': 0.4,\n",
    "                             'height_box':0.4,\n",
    "                             'ocr_proba_threshold':0.1, \n",
    "                             'mean_proba_threshold':0.7},\n",
    "                   'Description': {'page_0_lower': 0, \n",
    "                                   'page_0_upper':1/2, \n",
    "                                   'page_1_lower':1/2, \n",
    "                                   'page_1_upper':1,\n",
    "                                   'width_box': 0,\n",
    "                                   'height_box':0,\n",
    "                                   'ocr_proba_threshold':0.1, \n",
    "                                   'mean_proba_threshold':0.5}\n",
    "                  }\n",
    "\n",
    "def find_attributes():\n",
    "    attributes_bounds = []\n",
    "    pages = []\n",
    "    # Going through all the images\n",
    "    for filename in os.listdir(\"./data/Antigone/0_Images/\"):\n",
    "        if filename.endswith(\".jpg\"): \n",
    "            file_without_extension = os.path.splitext(filename)[0]\n",
    "            #print(file_without_extension)\n",
    "            pages.append(file_without_extension)\n",
    "            # Find attribute in the image\n",
    "            dict_bounds = find_attributes_one_image(file_without_extension)\n",
    "            attributes_bounds.append(dict_bounds)\n",
    "            #print(dict_bounds)\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "    return order_dict(dict(zip(pages, attributes_bounds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary = find_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_in_json(dictionnary, \"./data/Antigone/2_OCR_results/Antigone.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh_segment",
   "language": "python",
   "name": "dh_segment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
