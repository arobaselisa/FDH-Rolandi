{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import collections\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first start by loading the json data of our libretto which has the following structure:\n",
    "* A list of all scans of the libretto (one scan consists of 2 pages)\n",
    "* A list per scan containing 2 dictionnaries: one for the left page, which index is 0, and one for the right page, which index is 1.\n",
    "* For each index of the dictionnary is stored a list of elements figuring in the page and stored in the following way:\n",
    "    * `[Num:Int, Label:String, Text:String]`\n",
    "    * Num is the y-coordinate of the text in the page (if close to 0, then it is on top of the page)\n",
    "    * Label is one of the following label extracted: Name, Description or Scene\n",
    "    * Text is the written text figuring in the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_in_dict(path):\n",
    "    ''' \n",
    "    Loads ordered dictionnary of bounds per pages and per coordinates from a json file\n",
    "    :param string path: where all data of libretto is stored, as explained above\n",
    "    '''\n",
    "    with open(path) as json_file: \n",
    "        return json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json_in_dict(\"./data/Antigone/2_OCR_results/Antigone.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Text elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement the methods which will be useful to move from the structure which was specified above to the foloowing one:\n",
    "* Remove the pages and coordinates of each word appearing in the libretto\n",
    "* Remove all stopwords from the extracted text\n",
    "* For each label/attribute ('Scene', 'Description', 'Name'):\n",
    "    * Extract ['Label', 'Text] in the order they appear in the libretto and store it in `all_attributes`\n",
    "    * Create list of names, scenes and descriptions in the order they appear in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def remove_stopwords(text):\n",
    "    '''\n",
    "    Outputs text with removed stopwords in all kind of cases \n",
    "    :param string text: italian string text extracted from libretto\n",
    "    '''\n",
    "    #Create list of italian stopwords in all cases\n",
    "    stop_words = stopwords.words('italian')+[word.title() for word in stopwords.words('italian')]+[word.upper() for word in stopwords.words('italian')]\n",
    "    #Tokenize text and remove word if it is a stopword\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stop_words]\n",
    "    return tokens_without_sw\n",
    "\n",
    "def extract_all_attributes(data):\n",
    "    '''\n",
    "    Extract all atributes extracted by OCR in order, whithout storing coordinates or pages\n",
    "    :param list data: extracted italian text of libretto separated by pages and coordinates\n",
    "    '''\n",
    "    elements = np.empty(shape=(0,2))\n",
    "    # for each page of the libretto\n",
    "    for page in range(len(data)):\n",
    "        # for each left and/or right page\n",
    "        for ind in data[page][1].keys():\n",
    "            # extract elements in the order they appear, without storing coordinates or pages\n",
    "            elements = np.concatenate((elements, np.array(data[page][1][ind])[:, 1:]), axis = 0)\n",
    "    return elements\n",
    "\n",
    "def extract_attribute(elements, attribute):\n",
    "    '''\n",
    "    Extract elements in order from specific attribute\n",
    "    :param numpy.ndarray elements: elements ['Label', 'Text'] stored in the order they appear in \n",
    "    :param string attribute: the label/attribute to extract ('Name', 'Description', 'Scene')\n",
    "    '''\n",
    "    # Extract text from specific attribute\n",
    "    text_list = [row[1] for row in elements if attribute in row[0]]\n",
    "    # Create string\n",
    "    text = \" \".join(text_list)\n",
    "    # Remove digits\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    # Remove punctuations\n",
    "    text = text.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
    "    # Remove stopwords\n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attributes = extract_all_attributes(data)\n",
    "\n",
    "#Lists of text from the defined attribute\n",
    "description = extract_attribute(all_attributes, 'Description')\n",
    "names = extract_attribute(all_attributes, 'Name')\n",
    "scenes = extract_attribute(all_attributes, 'Scene')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal now is to be able to define which character figures in which scenes. As seen above, the `names` list contains abbreviations of the characters of the libretto. Their complete name figure in the `description` list which we need to extract based on the abbreviations we have. We will therefore proceed in the following way:\n",
    "* We extract the top_N most common abbreviations names figuring in the `names` list. We chose top_N = 15 as a libretto contains around 10 characters and as some frequent abbreviations had been misspelled by the OCR.\n",
    "* Based on the extracted abbreviation names, we now create a list of regex patterns to look for in the description. \n",
    "* We will then extract the most frequent complete name for each pattern.\n",
    "* We output a dictionnary which key is the most frequent complete name extracted from the pattern and the value is a list of all other words which has been extracted from the same pattern. This other words are not unique as we need them to define which key name is the most correct one for similar extracted key names (i.e. Autigona and Antigona are key extracted names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names_abbreviations(names, top_N=15):\n",
    "    '''\n",
    "    Extract top-N most common abbreviation names\n",
    "    :param list names: list of abbreviation names\n",
    "    :param int top_N, default=15: number of most common abbreviations names to extract\n",
    "    '''\n",
    "    #Create the list of abbreviation names to return\n",
    "    names_abbreviations = []\n",
    "    #Extract the top_N most common abbreviations names figuring in the list names\n",
    "    frequent_names = collections.Counter(names).most_common()[:top_N]\n",
    "    for name, count in frequent_names:\n",
    "        names_abbreviations.append(name)\n",
    "    return list(set(names_abbreviations))\n",
    "\n",
    "def list_patterns(names_abbreviations):\n",
    "    '''\n",
    "    Create list of patterns from abbreviation names\n",
    "    :param list names_abbreviations: list of unique abbreviation names\n",
    "    '''\n",
    "    #Create a pattern for each abbreviation name by adding a '.*' after each character\n",
    "    #This means that the character is followed by 0 or more other characters until it meets the next character \n",
    "    #of the pattern.\n",
    "    patterns = list(map('.*'.join, names_abbreviations))\n",
    "    #Creat a list of correct patterns to return\n",
    "    correct_patterns = []\n",
    "    #For each patter remove the '.*'following the first character of the name\n",
    "    for pattern in patterns:\n",
    "        correct_patterns.append(pattern.replace(\".*\", \"\", 1) + \".*\")\n",
    "    return correct_patterns\n",
    "\n",
    "def filter_pattern(pattern, description):\n",
    "    '''\n",
    "    Filter list of abbreviations by given pattern\n",
    "    :param string pattern: a regex pattern\n",
    "    :param list description: a list of text from which we need to extract words with the given pattern\n",
    "    '''\n",
    "    #list of all words from description which matched the pattern\n",
    "    occurences = [val for val in description if re.search(pattern, val)]\n",
    "    if len(occurences) > 0:\n",
    "        return occurences\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def find_complete_name(pattern, text, abbreviation):\n",
    "    '''\n",
    "    Returns most common name who follows the given pattern\n",
    "    :param string pattern: a regex pattern corresponding to the given abbreviation\n",
    "    :param string text: a list of text from which we need to extract words with the given pattern\n",
    "    :param string abbreviation: the abbreviation name for which the complete name is being searched\n",
    "    '''\n",
    "    #list of all words from text which matched the pattern\n",
    "    occurences = filter_pattern(pattern, text)\n",
    "    #Extract the most common word form the list of occurences\n",
    "    most_common_name = collections.Counter(occurences).most_common(1)\n",
    "    #If a name has been extracted from the list of occurences, then return it with all\n",
    "    #the other words matching the pattern as well as the abbreviation from ehich the pattern\n",
    "    #has been derived.\n",
    "    if (len(most_common_name) > 0) and (len(occurences) > 0):\n",
    "        return most_common_name[0][0], occurences+[abbreviation]\n",
    "    return  None, None\n",
    "    \n",
    "def extract_complete_names(names, description):\n",
    "    '''\n",
    "    Extract dictionnary of characters complete names and their respective similar names\n",
    "    :param list names: list of abbreviation names\n",
    "    :param list description: a list of text from which we need to extract words with the given pattern\n",
    "    '''\n",
    "    #Extract abbrevations names\n",
    "    names_abbreviations = extract_names_abbreviations(names)\n",
    "    #Extract patterns for each of the abreviation names\n",
    "    patterns = list_patterns(names_abbreviations)\n",
    "\n",
    "    #A dictionnary which will store for each most common complete name all occurences \n",
    "    #of words which come from the same pattern.\n",
    "    dic = {}\n",
    "    #For each abbreviation and pattern, we are going to find its most common complete name\n",
    "    for abbreviation, pattern in zip(names_abbreviations, patterns):\n",
    "        name, name_mappings = find_complete_name(pattern, description, abbreviation)\n",
    "        #Check whether a complete name was found in the description list of texts\n",
    "        if name != None:\n",
    "            #If the name is already contained in the dictionnary, then it means the pattern \n",
    "            #found many names which probably had been misspelled by the OCR and which we\n",
    "            #therefore need to correct.\n",
    "            if name in dic:\n",
    "                dic[name] =dic[name] + name_mappings\n",
    "            else:\n",
    "                dic[name] = name_mappings\n",
    "    return dic, names_abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic, abbreviations = extract_complete_names(names, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we achieved to extract the complete names for each abbreviation name as well as their respective list of names which follow the same pattern, we can now focus on extracting the correct true names. Indeed as mentionned before, one can get *Antigona* and *Autigona* which define one and only character which is *Antigona*. \n",
    "\n",
    "To be able to correct the extracted name *Autigona*, we will make use of similarity distances and in our case the levenshtein distancea string metric for measuring the difference between two words. The Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other.\n",
    "\n",
    "If two words are similar above some threshold, then the correct word/name to keep will be the one who had the longest list of extracted similar words coming from the same pattern.\n",
    "\n",
    "The goal now is to find for each abbreviation name which has been extracted the corresponding true complete name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher as sm\n",
    "\n",
    "def complete_names_to_correct(dic, threshold=0.60):\n",
    "    '''\n",
    "    Extract a dictionnary of complete names with their respective similar names and a set \n",
    "    complete names to remove if they are similar in the Levenshtein distance metric sense.\n",
    "    :param dictionnary dic: a dictionnary of characters complete names and their respective similar names\n",
    "    :param float threshold: the Levenshtein similitude ratio needed to confirm that two words are similar\n",
    "    '''\n",
    "    #The dictionnary which will store the similar complete names and their respective similar \n",
    "    #wording in the same key.\n",
    "    dic_new = {}\n",
    "    names_keys = list(dic.keys())\n",
    "    names_values = list(dic.values())\n",
    "    #The set of complete names to remove from the dictionnary as their are similar. Will be replaced correctly.\n",
    "    keys_to_remove = set()\n",
    "    #For each pair of complete names, check wether the names are similar\n",
    "    for i in range(len(names_keys)):\n",
    "        for j in range(i+1, len(names_keys)):\n",
    "            if(sm(None, names_keys[i], names_keys[j]).ratio() >= threshold):\n",
    "                #As the names are similar, check which of the two names has the longest \n",
    "                #list of extracted similar words coming from the same pattern. This will then\n",
    "                #be the correct complete name.\n",
    "                key_index = j if (len(names_values[i]) < len(names_values[j])) else i\n",
    "                keys_to_remove.add(names_keys[i])\n",
    "                keys_to_remove.add(names_keys[j])\n",
    "                if names_keys[key_index] in dic_new.keys():\n",
    "                    dic_new[names_keys[key_index]].extend(names_values[i])\n",
    "                    dic_new[names_keys[key_index]].extend(names_values[j])\n",
    "                else:\n",
    "                    dic_new[names_keys[key_index]] = names_values[i]\n",
    "                    dic_new[names_keys[key_index]].extend(names_values[j])\n",
    "    #Remove duplicates \n",
    "    dic_new = {k:list(set(j)) for k,j in dic_new.items()}\n",
    "    return dic_new, keys_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_names_corrected, names_to_remove = complete_names_to_correct(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_abbrev_with_complete_names(dic, names_to_remove, dic_names_corrected):\n",
    "    '''\n",
    "    Output the dictionnary which map abbreviation names with their correct complete name\n",
    "    :param dictionnary dic: a dictionnary of characters complete names and their respective similar names\n",
    "    :param set names_to_remove: a set of string complete names to remove as they match other names\n",
    "    :param dictionnary dic_names_corrected: a dictionnary of aggregated similar complete names\n",
    "    '''\n",
    "    #For all key names to remove, remove them from dictionnary of complete names\n",
    "    for k in names_to_remove :\n",
    "        dic.pop(k)\n",
    "    #Update the dictionnary of complete names with the names of the removed keys \n",
    "    dic.update(dic_names_corrected)\n",
    "    #Remove duplicates from the list of similar words for each key complete name \n",
    "    #in the dictionnary of complete names\n",
    "    dic = {k:list(set(j)) for k,j in dic.items()}\n",
    "    #For each complete name in the dictionnary, keep only the abbreviation names\n",
    "    for k,v in dic.items():\n",
    "        dic[k] = list(set(abbreviations) & set(v))\n",
    "    #Inverse the dictionnary to obtain as keys the abbreviation names and as values the complete name\n",
    "    #with which it will be replaced\n",
    "    dic_inv = {}\n",
    "    for key,list_val in dic.items():\n",
    "        for val in list_val:\n",
    "            dic_inv[val] = key\n",
    "    return dic_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_names = match_abbrev_with_complete_names(dic, names_to_remove, dic_names_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Scenes and Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_attributes(attributes, dic_names):\n",
    "    ''' \n",
    "    Adds the acts in the attributes and stores the scenes as numbers \n",
    "    :param list attributes: the list containing all attributes\n",
    "    :param dictionnary dic_names: the dictionnary which maps abbreviations with complete names\n",
    "    '''\n",
    "    attributes_clean = attributes.copy()\n",
    "    count_scene = 0\n",
    "    count_act = 0\n",
    "    mask = np.ones((np.shape(all_attributes)))\n",
    "    # Goes through all the list\n",
    "    for i, att in enumerate(all_attributes):\n",
    "        # through all the text that has the 'Scene' tag\n",
    "        if (att[0]=='Scene'):\n",
    "            # Remove punctuation and case\n",
    "            word = att[1].lower().translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
    "            # If a scene is the first one, we add the begining of an act\n",
    "            if (word=='prima'):\n",
    "                count_act += 1\n",
    "                count_scene = 0\n",
    "                attributes_clean[i] = ['Act', count_act]\n",
    "            # Detects the scene, stores its number\n",
    "            elif (word=='scena'):\n",
    "                count_scene += 1\n",
    "                attributes_clean[i] = ['Scene', count_scene]\n",
    "            else:\n",
    "            # Otherwise, we will delete this row\n",
    "                mask[i] = 0\n",
    "        if (att[0]=='Name'):\n",
    "            # Remove punctuation and case\n",
    "            word = att[1].translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
    "            if (word in dic_names.keys()):\n",
    "                attributes_clean[i] = ['Name', dic_names[word]]\n",
    "            else: \n",
    "                mask[i] = 0\n",
    "        if (att[0]=='Description'):\n",
    "            mask[i] = 0\n",
    "    # Delete rows that we don't need anymore\n",
    "    attributes_clean = attributes_clean[mask.astype(np.bool)]\n",
    "    attributes_clean = attributes_clean.reshape(int(np.shape(attributes_clean)[0]/2), 2)\n",
    "    return attributes_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_clean = clean_attributes(all_attributes, dic_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tree Structure for Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now store the extracted and cleaned information in a tree structure which will then be accesible in a json format. The tree structure will be created in the following way:\n",
    "* The root will be the libretto name (level 0).\n",
    "* The nodes in level 1 will be the Acts.\n",
    "* The children nodes in level 2 coming from one of the Act parent node will be the Scenes contained in the corresponding Act.\n",
    "* The children nodes in level 3 coming from one of the Scene parent node will be the Character names and the number of occurences of their name in the corresponding Scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(attributes_clean):\n",
    "    ''' \n",
    "    Create the tree structure of our libretto \n",
    "    :param numpy.ndarray attributes_clean: the list containing all attributes in the order of appearance\n",
    "    '''\n",
    "    #Creat dictionnary which will store the tree\n",
    "    final_dic = {}\n",
    "    #Loop through all cleaned attributes\n",
    "    for i, att in enumerate(attributes_clean):\n",
    "        #If attribute is 'Act' tag, create empty dictionnary to store the Scenes\n",
    "        if (att[0]=='Act'):\n",
    "            final_dic[int(att[1])] = {}\n",
    "        #If attribute is 'Scene' tag, stay in the least added Act and add an empty dictionnary to store the Names\n",
    "        if (att[0]=='Scene'):\n",
    "            dic_act = final_dic[list(final_dic.keys())[-1]]\n",
    "            dic_act[int(att[1])] = {}\n",
    "        #If attribute is 'Name' tag, stay in the least added Scene and add the Name in the dictionnary \n",
    "        #with a counter == 1. Each time the name reappers, add 1 to the counter. The counter represents the\n",
    "        #occurences of the name in the scene\n",
    "        if (att[0]=='Name'):\n",
    "            dic_act = final_dic[list(final_dic.keys())[-1]]\n",
    "            dict_scene = dic_act[list(dic_act.keys())[-1]]\n",
    "            if att[1] in dict_scene.keys():\n",
    "                dict_scene[att[1]] += 1\n",
    "            else:\n",
    "                dict_scene[att[1]] = 1\n",
    "    return final_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = create_tree(attributes_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now save that tree structure in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_in_json(dictionnary, path):\n",
    "    ''' Saves ordered dictionnary of bounds per pages and per coordinates in a json file'''\n",
    "    with open(path, \"w\") as outfile:  \n",
    "        json.dump(dictionnary, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_in_json(tree, \"./data/Antigone/3_Network/network.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh_segment",
   "language": "python",
   "name": "dh_segment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
